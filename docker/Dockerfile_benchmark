#syntax=docker/dockerfile:1.2
FROM nvidia/cuda:11.7.1-devel-ubuntu20.04 as base

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:/usr/local/lib" \
    PYTHONIOENCODING=UTF-8 \
    LANG=C.UTF-8 \
    LC_ALL=C.UTF-8 \
    SHELL=/bin/bash

RUN --mount=type=cache,target=/var/cache/apt --mount=type=cache,target=/var/lib/apt \
    export DEBIAN_FRONTEND=noninteractive && \
    apt-get update && \
    apt-get install -y \
        build-essential autoconf libtool cmake ninja-build fuse iproute2 \
        libcudnn8 libcudnn8-dev \
        libzstd-dev wget git unzip python3-dev python3-pip && \
    rm -rf /var/lib/apt/lists/*

# Require ccache>=3.7.9 to cache nvcc outputs
RUN cd /usr/local/src && \
    git clone --recursive https://github.com/ccache/ccache.git && \
    cd ccache && \
    git checkout v4.3 && \
    mkdir build; cd build; cmake -GNinja -DCMAKE_BUILD_TYPE=Release .. && \
    ninja && ninja install && \
    cd /usr/local/src && \
    ln -s /usr/local/bin/ccache /usr/local/bin/nvcc && \
    rm -rf ccache

# EFA Support
ENV LD_LIBRARY_PATH=/usr/local/src/nccl/build/lib:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/openmpi/lib:/opt/amazon/efa/lib:/opt/aws-ofi-nccl/install/lib:$LD_LIBRARY_PATH
ENV PATH=/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin:$PATH
RUN --mount=type=cache,target=/var/cache/apt --mount=type=cache,target=/var/lib/apt \
    apt-get update && apt-get install -y nvidia-fabricmanager-470 datacenter-gpu-manager && \
    apt-get purge --allow-change-held-packages -y libnccl2 libnccl-dev && \
    cd /usr/local/src && \
    wget https://efa-installer.amazonaws.com/aws-efa-installer-1.15.2.tar.gz && \
    tar -xf aws-efa-installer-1.15.2.tar.gz && \
    cd aws-efa-installer && \
    ./efa_installer.sh -y -g -d --skip-kmod --skip-limit-conf --no-verify && \
    cd /usr/local/src && rm -rf aws-efa-installer-latest.tar.gz aws-efa-installer && \
    cd /usr/local/src && git clone -b v2.13.4-1 https://github.com/NVIDIA/nccl.git && cd nccl && \
    make -j src.build CUDA_HOME=/usr/local/cuda \
      NVCC_GENCODE="-gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_70,code=sm_70" && \
      make install && \
    git clone -b aws https://github.com/aws/aws-ofi-nccl.git /opt/aws-ofi-nccl && \
    cd /opt/aws-ofi-nccl && \
    # v1.2.0 + EFA -FI_EAGAIN fix + nccl 2.12 fix
    git checkout 06b5390f1dc06a2b598954a3b0dd10fb8398f46e && \
    ./autogen.sh && \
    ./configure --prefix=/opt/aws-ofi-nccl/install \
      --with-libfabric=/opt/amazon/efa/ \
      --with-cuda=/usr/local/cuda \
      --with-nccl=/usr/ \
      --with-mpi=/opt/amazon/openmpi/ && \
    make && make install && \
    rm -rf /var/lib/apt/lists/*


# LD_PRELOAD trick to load binary torch with custom libnccl.so (unsupported)
# ENV LD_PRELOAD=/usr/local/src/nccl/build/lib/libnccl.so
RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.ccache  \
    python3 -m pip install awscli pyarrow scikit-build pyyaml typing-extensions numpy regex && \
    cd /usr/local/src/ && \
    # Depends on LD_PRELOAD trick
    git clone --recursive -j$(nproc) -b release/1.13 https://github.com/pytorch/pytorch  && \
    cd pytorch && \
    git submodule sync && \
    git submodule update --init --recursive  && \
    TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" USE_SYSTEM_NCCL=ON BUILD_CAFFE2_OPS=0 BUILD_CAFFE2=0 USE_MPI=0 \
        CUDA_NVCC_EXECUTABLE=/usr/local/bin/nvcc python3 setup.py install && \
    cd /usr/local/src/ && rm -rf pytorch


RUN apt-get update -y && apt-get install libaio-dev -y

RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.ccache  \ 
    cd /usr/local/src/ && \
    git clone -j$(nproc) -b ms/debug https://github.com/zarzen/ZeRO-2D  && \
    cd ZeRO-2D && \
    TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" DS_BUILD_OPS=1 DS_BUILD_SPARSE_ATTN=0 pip3 install . --no-build-isolation && \
    cd /usr/local/src/ && rm -rf ZeRO-2D

RUN --mount=type=cache,target=/root/.cache/pip --mount=type=cache,target=/root/.ccache  \
    cd /usr/local/src/ && \
    python3 -m pip install transformers datasets mock networkx && \
    git clone https://github.com/facebookresearch/xformers && \
    cd xformers && \
    git checkout 48a77cc && \
    git submodule sync && git submodule update --init --recursive && \
    FORCE_CUDA="1" TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" pip3 install -e . && \
    cd /usr/local/src/ && \
    git clone https://github.com/jfc4050/flash-attention.git && \
    cd flash-attention && git checkout triton-dropout && \
    FORCE_CUDA="1" TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" pip3 install -v . && \
    git clone --recursive https://github.com/comaniac/epoi.git && \
    cd epoi && git fetch && git checkout fa90fa7 && pip3 install . && \
    cd /usr/local/src/ && rm -rf epoi && \
    git clone https://github.com/awslabs/slapo.git && \
    cd slapo && pip3 install -e ".[dev]" && \
    cd benchmark/ && \
    bash download_benchmark_dataset.sh

COPY xformers_patch /usr/local/src/xformers_patch


RUN XFORMER_PATH=`python3 -c "import xformers, pathlib; print(pathlib.Path(xformers.__path__[0]).parent)"` && \
    cd /usr/local/src && cp xformers_patch $XFORMER_PATH && \
    cd $XFORMER_PATH && \
    git config --global --add safe.directory $XFORMER_PATH && \
    git reset --hard && \
    git apply xformers_patch && \
    git --no-pager diff

RUN apt-get update -y && apt-get install vim -y


# SSH Support
RUN apt-get update -y && \
    apt-get upgrade -y && \
    apt-get install -y openssh-client openssh-server

RUN ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa && \
    cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys

RUN /usr/sbin/service ssh start

RUN apt-get install pdsh -y && apt install screen -y

RUN pip3 install ClusterShell

RUN MPICC=/opt/amazon/openmpi/bin/mpicc pip3 install mpi4py

RUN echo "Host * \n StrictHostKeyChecking no" > /root/.ssh/config

COPY .deepspeed_env /root/.deepspeed_env

RUN pip3 install torchvision==0.14.0 --no-deps && \
    pip3 install image && \
    pip3 install pybind11

RUN cd /usr/local/src/ && \
    git clone https://github.com/NVIDIA/apex && \
    cd apex && \
    FORCE_CUDA="1" TORCH_CUDA_ARCH_LIST="8.0 7.5 7.0" pip3 install -v --disable-pip-version-check --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./

RUN pip3 install numpy==1.23.0
